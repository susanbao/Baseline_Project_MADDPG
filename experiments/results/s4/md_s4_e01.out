[Discrete(8), Discrete(10), Discrete(10)]
There is 3 adversaries
Using good policy maddpg and adv policy maddpg
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -29.853294719807398, agent episode reward: [-41.77090654457902, 5.958805912385807, 5.958805912385807], time: 80.398
steps: 49975, episodes: 2000, mean episode reward: -34.16584047728213, agent episode reward: [-59.25969992295366, 12.546929722835765, 12.546929722835765], time: 95.807
steps: 74975, episodes: 3000, mean episode reward: -9.772928905291302, agent episode reward: [-22.695968445786594, 6.461519770247645, 6.461519770247645], time: 96.746
steps: 99975, episodes: 4000, mean episode reward: -9.69884525648379, agent episode reward: [-21.513401986828377, 5.907278365172292, 5.907278365172292], time: 96.859
steps: 124975, episodes: 5000, mean episode reward: -10.037748031584778, agent episode reward: [-22.15461805864936, 6.058435013532289, 6.058435013532289], time: 96.322
steps: 149975, episodes: 6000, mean episode reward: -9.869811406239377, agent episode reward: [-19.533804694334016, 4.83199664404732, 4.83199664404732], time: 96.78
steps: 174975, episodes: 7000, mean episode reward: -11.25422131481302, agent episode reward: [-20.46389959173576, 4.604839138461371, 4.604839138461371], time: 95.923
steps: 199975, episodes: 8000, mean episode reward: -10.528933367394325, agent episode reward: [-21.27002595318675, 5.370546292896211, 5.370546292896211], time: 97.287
steps: 224975, episodes: 9000, mean episode reward: -10.860774724791481, agent episode reward: [-21.79186062385493, 5.465542949531724, 5.465542949531724], time: 98.114
steps: 249975, episodes: 10000, mean episode reward: -11.374104026826735, agent episode reward: [-22.18920322281566, 5.407549597994463, 5.407549597994463], time: 96.914
steps: 274975, episodes: 11000, mean episode reward: -11.516465144749125, agent episode reward: [-22.949960916115035, 5.716747885682956, 5.716747885682956], time: 96.437
steps: 299975, episodes: 12000, mean episode reward: -12.182028058057346, agent episode reward: [-24.283964360712673, 6.0509681513276625, 6.0509681513276625], time: 96.384
steps: 324975, episodes: 13000, mean episode reward: -12.177296636593432, agent episode reward: [-25.096914977183093, 6.45980917029483, 6.45980917029483], time: 97.655
steps: 349975, episodes: 14000, mean episode reward: -12.930970219830108, agent episode reward: [-26.460789399459404, 6.76490958981465, 6.76490958981465], time: 98.814
steps: 374975, episodes: 15000, mean episode reward: -12.742662225861123, agent episode reward: [-25.439037388621195, 6.348187581380037, 6.348187581380037], time: 98.046
steps: 399975, episodes: 16000, mean episode reward: -12.923697826024611, agent episode reward: [-24.826295579549775, 5.951298876762584, 5.951298876762584], time: 97.946
steps: 424975, episodes: 17000, mean episode reward: -14.488841570965615, agent episode reward: [-25.931431707264377, 5.721295068149378, 5.721295068149378], time: 96.008
steps: 449975, episodes: 18000, mean episode reward: -13.792545694085453, agent episode reward: [-26.240969984293674, 6.2242121451041115, 6.2242121451041115], time: 95.171
steps: 474975, episodes: 19000, mean episode reward: -13.99823511024032, agent episode reward: [-26.43272921435247, 6.217247052056076, 6.217247052056076], time: 96.044
steps: 499975, episodes: 20000, mean episode reward: -13.532185035767183, agent episode reward: [-28.482871966130997, 7.475343465181904, 7.475343465181904], time: 97.172
steps: 524975, episodes: 21000, mean episode reward: -14.168097419611982, agent episode reward: [-27.899252269151454, 6.865577424769736, 6.865577424769736], time: 96.349
steps: 549975, episodes: 22000, mean episode reward: -13.73468915369949, agent episode reward: [-26.302903286232404, 6.284107066266457, 6.284107066266457], time: 96.811
steps: 574975, episodes: 23000, mean episode reward: -13.804478405257345, agent episode reward: [-26.43041566293058, 6.312968628836618, 6.312968628836618], time: 94.925
steps: 599975, episodes: 24000, mean episode reward: -13.489225300039827, agent episode reward: [-28.73647778611888, 7.623626243039526, 7.623626243039526], time: 96.722
steps: 624975, episodes: 25000, mean episode reward: -12.867107485291239, agent episode reward: [-27.239385433223397, 7.186138973966078, 7.186138973966078], time: 96.585
steps: 649975, episodes: 26000, mean episode reward: -13.644270332152232, agent episode reward: [-27.65813313332825, 7.00693140058801, 7.00693140058801], time: 96.586
steps: 674975, episodes: 27000, mean episode reward: -12.951413562491188, agent episode reward: [-28.917535456638202, 7.983060947073505, 7.983060947073505], time: 96.926
steps: 699975, episodes: 28000, mean episode reward: -13.056830746550334, agent episode reward: [-25.494895095348475, 6.219032174399071, 6.219032174399071], time: 95.839
steps: 724975, episodes: 29000, mean episode reward: -13.846819193577604, agent episode reward: [-25.342338066379785, 5.747759436401089, 5.747759436401089], time: 97.939
steps: 749975, episodes: 30000, mean episode reward: -13.470507231944598, agent episode reward: [-26.199369268682304, 6.364431018368855, 6.364431018368855], time: 97.765
steps: 774975, episodes: 31000, mean episode reward: -13.635152488630355, agent episode reward: [-26.019049629521025, 6.1919485704453345, 6.1919485704453345], time: 97.48
steps: 799975, episodes: 32000, mean episode reward: -14.103257948047617, agent episode reward: [-26.02656144923574, 5.961651750594061, 5.961651750594061], time: 97.125
steps: 824975, episodes: 33000, mean episode reward: -14.188775893330538, agent episode reward: [-26.10233373860424, 5.956778922636852, 5.956778922636852], time: 97.129
steps: 849975, episodes: 34000, mean episode reward: -14.094265120385776, agent episode reward: [-25.947032595687183, 5.926383737650703, 5.926383737650703], time: 97.857
steps: 874975, episodes: 35000, mean episode reward: -13.946109108037271, agent episode reward: [-27.638755678478184, 6.846323285220456, 6.846323285220456], time: 97.558
steps: 899975, episodes: 36000, mean episode reward: -13.239134215742004, agent episode reward: [-24.90530554696475, 5.8330856656113745, 5.8330856656113745], time: 97.145
steps: 924975, episodes: 37000, mean episode reward: -14.23128726034979, agent episode reward: [-25.606240946738204, 5.687476843194204, 5.687476843194204], time: 97.592
steps: 949975, episodes: 38000, mean episode reward: -14.817664515367516, agent episode reward: [-24.614500225903903, 4.898417855268193, 4.898417855268193], time: 99.856
steps: 974975, episodes: 39000, mean episode reward: -14.743949015683349, agent episode reward: [-25.67157375086048, 5.463812367588568, 5.463812367588568], time: 98.653
steps: 999975, episodes: 40000, mean episode reward: -15.00851223871126, agent episode reward: [-26.885042898511678, 5.93826532990021, 5.93826532990021], time: 97.404
steps: 1024975, episodes: 41000, mean episode reward: -14.811421888911575, agent episode reward: [-26.533231747745003, 5.860904929416713, 5.860904929416713], time: 97.199
steps: 1049975, episodes: 42000, mean episode reward: -13.909448503271495, agent episode reward: [-26.9368075526419, 6.513679524685205, 6.513679524685205], time: 97.983
steps: 1074975, episodes: 43000, mean episode reward: -14.178566378641506, agent episode reward: [-24.98596417249707, 5.403698896927784, 5.403698896927784], time: 97.778
steps: 1099975, episodes: 44000, mean episode reward: -14.116875249277145, agent episode reward: [-26.04777190928053, 5.965448330001694, 5.965448330001694], time: 97.644
steps: 1124975, episodes: 45000, mean episode reward: -14.675087424764174, agent episode reward: [-24.902388395041545, 5.113650485138684, 5.113650485138684], time: 96.626
steps: 1149975, episodes: 46000, mean episode reward: -13.082001820485576, agent episode reward: [-25.503674839459148, 6.210836509486785, 6.210836509486785], time: 95.527
steps: 1174975, episodes: 47000, mean episode reward: -13.657430520383661, agent episode reward: [-23.861275718582554, 5.101922599099446, 5.101922599099446], time: 97.399
steps: 1199975, episodes: 48000, mean episode reward: -13.306827253429402, agent episode reward: [-23.430360345675723, 5.06176654612316, 5.06176654612316], time: 98.169
steps: 1224975, episodes: 49000, mean episode reward: -14.37291843884021, agent episode reward: [-24.195941720440935, 4.911511640800364, 4.911511640800364], time: 98.063
steps: 1249975, episodes: 50000, mean episode reward: -14.31043736752563, agent episode reward: [-23.48796676206578, 4.588764697270075, 4.588764697270075], time: 98.268
steps: 1274975, episodes: 51000, mean episode reward: -14.375581873788091, agent episode reward: [-22.86025117736724, 4.242334651789573, 4.242334651789573], time: 97.678
steps: 1299975, episodes: 52000, mean episode reward: -14.808568564852765, agent episode reward: [-22.774157019132407, 3.9827942271398222, 3.9827942271398222], time: 98.701
steps: 1324975, episodes: 53000, mean episode reward: -14.618841259623837, agent episode reward: [-22.9784101906605, 4.179784465518331, 4.179784465518331], time: 98.384
steps: 1349975, episodes: 54000, mean episode reward: -14.703586891801486, agent episode reward: [-21.321422632020944, 3.308917870109731, 3.308917870109731], time: 97.272
steps: 1374975, episodes: 55000, mean episode reward: -14.821074262783975, agent episode reward: [-21.333335922112987, 3.256130829664506, 3.256130829664506], time: 97.593
steps: 1399975, episodes: 56000, mean episode reward: -16.076791391986138, agent episode reward: [-22.31509530353253, 3.1191519557731953, 3.1191519557731953], time: 97.862
steps: 1424975, episodes: 57000, mean episode reward: -15.60861405938656, agent episode reward: [-21.765279067596616, 3.078332504105029, 3.078332504105029], time: 98.1
steps: 1449975, episodes: 58000, mean episode reward: -16.425248228843905, agent episode reward: [-22.644584115530943, 3.1096679433435175, 3.1096679433435175], time: 97.076
steps: 1474975, episodes: 59000, mean episode reward: -16.37282546485006, agent episode reward: [-21.9170663716372, 2.772120453393568, 2.772120453393568], time: 97.664
steps: 1499975, episodes: 60000, mean episode reward: -15.572486544161322, agent episode reward: [-21.764733301756017, 3.096123378797347, 3.096123378797347], time: 93.806
...Finished total of 60001 episodes.
