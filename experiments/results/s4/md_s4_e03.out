[Discrete(8), Discrete(10), Discrete(10)]
There is 3 adversaries
Using good policy maddpg and adv policy maddpg
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -22.47013960318834, agent episode reward: [-40.83064435608211, 9.180252376446884, 9.180252376446884], time: 77.575
steps: 49975, episodes: 2000, mean episode reward: -19.67013037673541, agent episode reward: [-31.48920669312698, 5.909538158195785, 5.909538158195785], time: 94.136
steps: 74975, episodes: 3000, mean episode reward: -6.929158719823537, agent episode reward: [-20.89342724470915, 6.982134262442806, 6.982134262442806], time: 93.276
steps: 99975, episodes: 4000, mean episode reward: -6.740206001215454, agent episode reward: [-21.489450499768886, 7.3746222492767135, 7.3746222492767135], time: 92.573
steps: 124975, episodes: 5000, mean episode reward: -6.549670321008327, agent episode reward: [-21.735076530898485, 7.59270310494508, 7.59270310494508], time: 92.03
steps: 149975, episodes: 6000, mean episode reward: -6.604088645055143, agent episode reward: [-21.173357227688022, 7.28463429131644, 7.28463429131644], time: 92.605
steps: 174975, episodes: 7000, mean episode reward: -7.714599464725766, agent episode reward: [-21.400324820917408, 6.842862678095822, 6.842862678095822], time: 92.609
steps: 199975, episodes: 8000, mean episode reward: -6.278783298067456, agent episode reward: [-20.99490303974285, 7.358059870837699, 7.358059870837699], time: 93.429
steps: 224975, episodes: 9000, mean episode reward: -7.365658214544455, agent episode reward: [-21.954033117215847, 7.294187451335696, 7.294187451335696], time: 93.933
steps: 249975, episodes: 10000, mean episode reward: -7.528081460608313, agent episode reward: [-22.19507391569841, 7.333496227545049, 7.333496227545049], time: 92.473
steps: 274975, episodes: 11000, mean episode reward: -6.963616448280407, agent episode reward: [-21.880868659851185, 7.458626105785387, 7.458626105785387], time: 92.529
steps: 299975, episodes: 12000, mean episode reward: -7.539931149434155, agent episode reward: [-21.376656831631283, 6.918362841098563, 6.918362841098563], time: 93.315
steps: 324975, episodes: 13000, mean episode reward: -8.672417901771489, agent episode reward: [-22.50655304740969, 6.917067572819098, 6.917067572819098], time: 93.255
steps: 349975, episodes: 14000, mean episode reward: -8.866481747329976, agent episode reward: [-21.761096845913702, 6.447307549291863, 6.447307549291863], time: 93.41
steps: 374975, episodes: 15000, mean episode reward: -9.696712203949177, agent episode reward: [-23.06551039166138, 6.684399093856102, 6.684399093856102], time: 93.878
steps: 399975, episodes: 16000, mean episode reward: -9.696105585944373, agent episode reward: [-22.438077180229598, 6.37098579714261, 6.37098579714261], time: 93.334
steps: 424975, episodes: 17000, mean episode reward: -9.709573080070532, agent episode reward: [-22.615496065121658, 6.452961492525563, 6.452961492525563], time: 93.573
steps: 449975, episodes: 18000, mean episode reward: -9.232019444382658, agent episode reward: [-21.79470154899498, 6.28134105230616, 6.28134105230616], time: 94.127
steps: 474975, episodes: 19000, mean episode reward: -9.641456432912612, agent episode reward: [-22.239082168424375, 6.298812867755882, 6.298812867755882], time: 94.467
steps: 499975, episodes: 20000, mean episode reward: -10.45696173787904, agent episode reward: [-22.382106296618414, 5.96257227936969, 5.96257227936969], time: 93.817
steps: 524975, episodes: 21000, mean episode reward: -10.04381822518605, agent episode reward: [-22.83200964252466, 6.394095708669306, 6.394095708669306], time: 94.028
steps: 549975, episodes: 22000, mean episode reward: -9.268178642437778, agent episode reward: [-22.80883510426691, 6.770328230914566, 6.770328230914566], time: 93.46
steps: 574975, episodes: 23000, mean episode reward: -9.987393437862298, agent episode reward: [-22.424015951549357, 6.2183112568435295, 6.2183112568435295], time: 93.978
steps: 599975, episodes: 24000, mean episode reward: -9.737825074208315, agent episode reward: [-22.243581015405436, 6.252877970598562, 6.252877970598562], time: 94.237
steps: 624975, episodes: 25000, mean episode reward: -9.249390594492535, agent episode reward: [-22.448123445064123, 6.599366425285794, 6.599366425285794], time: 92.712
steps: 649975, episodes: 26000, mean episode reward: -9.733563542967595, agent episode reward: [-22.502288448579115, 6.384362452805759, 6.384362452805759], time: 94.344
steps: 674975, episodes: 27000, mean episode reward: -10.005145894349516, agent episode reward: [-22.19932266641983, 6.097088386035157, 6.097088386035157], time: 93.988
steps: 699975, episodes: 28000, mean episode reward: -10.510591843905285, agent episode reward: [-22.014992559818005, 5.752200357956361, 5.752200357956361], time: 94.532
steps: 724975, episodes: 29000, mean episode reward: -9.718254581976106, agent episode reward: [-21.77613991854147, 6.0289426682826806, 6.0289426682826806], time: 94.152
steps: 749975, episodes: 30000, mean episode reward: -10.809043480554662, agent episode reward: [-22.661928181357304, 5.926442350401319, 5.926442350401319], time: 93.957
steps: 774975, episodes: 31000, mean episode reward: -10.03818968286744, agent episode reward: [-21.84152302109544, 5.901666669114, 5.901666669114], time: 93.865
steps: 799975, episodes: 32000, mean episode reward: -9.792476304607801, agent episode reward: [-21.642979099913838, 5.925251397653018, 5.925251397653018], time: 93.912
steps: 824975, episodes: 33000, mean episode reward: -9.939449860996257, agent episode reward: [-22.40601548413807, 6.233282811570906, 6.233282811570906], time: 94.153
steps: 849975, episodes: 34000, mean episode reward: -9.626562164706188, agent episode reward: [-21.57330148411297, 5.9733696597033905, 5.9733696597033905], time: 94.072
steps: 874975, episodes: 35000, mean episode reward: -9.984761918546262, agent episode reward: [-22.787122028835576, 6.401180055144657, 6.401180055144657], time: 93.849
steps: 899975, episodes: 36000, mean episode reward: -9.313732726956209, agent episode reward: [-23.15820591056769, 6.92223659180574, 6.92223659180574], time: 94.162
steps: 924975, episodes: 37000, mean episode reward: -10.223609737240967, agent episode reward: [-21.84512813217871, 5.810759197468871, 5.810759197468871], time: 94.392
steps: 949975, episodes: 38000, mean episode reward: -9.970463025052638, agent episode reward: [-23.17475714189119, 6.602147058419276, 6.602147058419276], time: 93.762
steps: 974975, episodes: 39000, mean episode reward: -10.186035397613189, agent episode reward: [-22.77657484843868, 6.295269725412747, 6.295269725412747], time: 94.566
steps: 999975, episodes: 40000, mean episode reward: -9.842143522642406, agent episode reward: [-22.065669783930872, 6.111763130644233, 6.111763130644233], time: 94.025
steps: 1024975, episodes: 41000, mean episode reward: -9.584729446281656, agent episode reward: [-22.1879462093602, 6.30160838153927, 6.30160838153927], time: 94.095
steps: 1049975, episodes: 42000, mean episode reward: -8.958145557600353, agent episode reward: [-22.169441992850064, 6.605648217624855, 6.605648217624855], time: 94.541
steps: 1074975, episodes: 43000, mean episode reward: -9.944025373763466, agent episode reward: [-22.432729907756155, 6.244352266996343, 6.244352266996343], time: 93.472
steps: 1099975, episodes: 44000, mean episode reward: -10.28528946976709, agent episode reward: [-21.679512559768288, 5.6971115450006, 5.6971115450006], time: 94.226
steps: 1124975, episodes: 45000, mean episode reward: -10.652710099465644, agent episode reward: [-23.03924548548176, 6.1932676930080595, 6.1932676930080595], time: 94.223
steps: 1149975, episodes: 46000, mean episode reward: -10.63659421398658, agent episode reward: [-21.71414407108679, 5.538774928550106, 5.538774928550106], time: 93.72
steps: 1174975, episodes: 47000, mean episode reward: -10.249909190848165, agent episode reward: [-22.251891461695564, 6.000991135423699, 6.000991135423699], time: 93.425
steps: 1199975, episodes: 48000, mean episode reward: -10.114430087601077, agent episode reward: [-21.944803650886776, 5.915186781642849, 5.915186781642849], time: 93.471
steps: 1224975, episodes: 49000, mean episode reward: -10.68638560560012, agent episode reward: [-22.15304939286493, 5.733331893632405, 5.733331893632405], time: 93.474
steps: 1249975, episodes: 50000, mean episode reward: -10.694015055582135, agent episode reward: [-22.2499631432447, 5.777974043831282, 5.777974043831282], time: 94.783
steps: 1274975, episodes: 51000, mean episode reward: -11.645863159481486, agent episode reward: [-22.578934361833674, 5.466535601176094, 5.466535601176094], time: 93.747
steps: 1299975, episodes: 52000, mean episode reward: -10.947441226716052, agent episode reward: [-22.297950490431838, 5.675254631857893, 5.675254631857893], time: 94.244
steps: 1324975, episodes: 53000, mean episode reward: -11.22709018916414, agent episode reward: [-23.143159097133104, 5.958034453984479, 5.958034453984479], time: 94.272
steps: 1349975, episodes: 54000, mean episode reward: -10.613323833021491, agent episode reward: [-21.309313966684073, 5.3479950668312926, 5.3479950668312926], time: 94.17
steps: 1374975, episodes: 55000, mean episode reward: -11.763270429096632, agent episode reward: [-22.151139424653586, 5.193934497778476, 5.193934497778476], time: 93.986
steps: 1399975, episodes: 56000, mean episode reward: -11.199845491125263, agent episode reward: [-23.365038232951523, 6.082596370913131, 6.082596370913131], time: 93.897
steps: 1424975, episodes: 57000, mean episode reward: -10.739775429107478, agent episode reward: [-23.457941736255325, 6.359083153573923, 6.359083153573923], time: 93.776
steps: 1449975, episodes: 58000, mean episode reward: -11.094089641827784, agent episode reward: [-22.99384078860603, 5.949875573389126, 5.949875573389126], time: 93.843
steps: 1474975, episodes: 59000, mean episode reward: -11.41893030286585, agent episode reward: [-24.153220301964616, 6.3671449995493825, 6.3671449995493825], time: 93.668
steps: 1499975, episodes: 60000, mean episode reward: -11.939058649772825, agent episode reward: [-22.648063070348428, 5.354502210287803, 5.354502210287803], time: 94.326
...Finished total of 60001 episodes.
